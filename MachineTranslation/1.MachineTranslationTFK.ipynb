{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"deu-eng/deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Be kind.', 'Sei nett!',\n",
       "       'CC-BY 2.0 (France) Attribution: tatoeba.org #1916315 (CK) & #1998565 (Tamy)'],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Text Pre-Processing'''\n",
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
    "\n",
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower() \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Text to Sequence Conversion'''\n",
    "\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6243\n",
      "Deutch Vocabulary Size: 10329\n"
     ]
    }
   ],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# preparing english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "\n",
    "# preparing Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Padding'''\n",
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model Building'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "#splitting \n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''optimizer '''\n",
    "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n",
    "# 'sparse_categorical_crossentropy' as the loss function allows us to use the target sequence as it is instead of one hot encoded format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 3.4173\n",
      "Epoch 00001: val_loss improved from inf to 2.89507, saving model to MTmodel.h1.24_Aug_20\n",
      "WARNING:tensorflow:From /Users/tejask/opt/anaconda3/envs/TFK/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/tejask/opt/anaconda3/envs/TFK/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 127s 2s/step - loss: 3.4173 - val_loss: 2.8951\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.7831\n",
      "Epoch 00002: val_loss improved from 2.89507 to 2.82129, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 120s 2s/step - loss: 2.7831 - val_loss: 2.8213\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.6311\n",
      "Epoch 00003: val_loss improved from 2.82129 to 2.57989, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 125s 2s/step - loss: 2.6311 - val_loss: 2.5799\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.4599\n",
      "Epoch 00004: val_loss improved from 2.57989 to 2.46380, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 128s 2s/step - loss: 2.4599 - val_loss: 2.4638\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.3176\n",
      "Epoch 00005: val_loss improved from 2.46380 to 2.34780, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 131s 2s/step - loss: 2.3176 - val_loss: 2.3478\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.1858 \n",
      "Epoch 00006: val_loss improved from 2.34780 to 2.24404, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 2264s 36s/step - loss: 2.1858 - val_loss: 2.2440\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 2.0690\n",
      "Epoch 00007: val_loss improved from 2.24404 to 2.18023, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 162s 3s/step - loss: 2.0690 - val_loss: 2.1802\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.9577\n",
      "Epoch 00008: val_loss improved from 2.18023 to 2.07550, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 137s 2s/step - loss: 1.9577 - val_loss: 2.0755\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.8526\n",
      "Epoch 00009: val_loss improved from 2.07550 to 2.01181, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 125s 2s/step - loss: 1.8526 - val_loss: 2.0118\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.7511\n",
      "Epoch 00010: val_loss improved from 2.01181 to 1.92074, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 124s 2s/step - loss: 1.7511 - val_loss: 1.9207\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.6478\n",
      "Epoch 00011: val_loss improved from 1.92074 to 1.86878, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 128s 2s/step - loss: 1.6478 - val_loss: 1.8688\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.5482\n",
      "Epoch 00012: val_loss improved from 1.86878 to 1.79154, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 130s 2s/step - loss: 1.5482 - val_loss: 1.7915\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.4543\n",
      "Epoch 00013: val_loss improved from 1.79154 to 1.72646, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 129s 2s/step - loss: 1.4543 - val_loss: 1.7265\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.3660\n",
      "Epoch 00014: val_loss improved from 1.72646 to 1.68999, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 131s 2s/step - loss: 1.3660 - val_loss: 1.6900\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2809\n",
      "Epoch 00015: val_loss improved from 1.68999 to 1.63141, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 132s 2s/step - loss: 1.2809 - val_loss: 1.6314\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2015\n",
      "Epoch 00016: val_loss improved from 1.63141 to 1.58328, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 134s 2s/step - loss: 1.2015 - val_loss: 1.5833\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.1238\n",
      "Epoch 00017: val_loss improved from 1.58328 to 1.56798, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 144s 2s/step - loss: 1.1238 - val_loss: 1.5680\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.0515\n",
      "Epoch 00018: val_loss improved from 1.56798 to 1.50676, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 137s 2s/step - loss: 1.0515 - val_loss: 1.5068\n",
      "Epoch 19/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9804\n",
      "Epoch 00019: val_loss improved from 1.50676 to 1.47821, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 138s 2s/step - loss: 0.9804 - val_loss: 1.4782\n",
      "Epoch 20/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9145\n",
      "Epoch 00020: val_loss improved from 1.47821 to 1.44149, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 140s 2s/step - loss: 0.9145 - val_loss: 1.4415\n",
      "Epoch 21/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8503\n",
      "Epoch 00021: val_loss improved from 1.44149 to 1.42234, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 1958s 31s/step - loss: 0.8503 - val_loss: 1.4223\n",
      "Epoch 22/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7897\n",
      "Epoch 00022: val_loss improved from 1.42234 to 1.40222, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 111s 2s/step - loss: 0.7897 - val_loss: 1.4022\n",
      "Epoch 23/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7322\n",
      "Epoch 00023: val_loss did not improve from 1.40222\n",
      "63/63 [==============================] - 101s 2s/step - loss: 0.7322 - val_loss: 1.4087\n",
      "Epoch 24/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6801\n",
      "Epoch 00024: val_loss improved from 1.40222 to 1.35425, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 118s 2s/step - loss: 0.6801 - val_loss: 1.3543\n",
      "Epoch 25/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6291\n",
      "Epoch 00025: val_loss improved from 1.35425 to 1.34209, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 120s 2s/step - loss: 0.6291 - val_loss: 1.3421\n",
      "Epoch 26/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5822\n",
      "Epoch 00026: val_loss improved from 1.34209 to 1.32987, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 122s 2s/step - loss: 0.5822 - val_loss: 1.3299\n",
      "Epoch 27/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5351\n",
      "Epoch 00027: val_loss improved from 1.32987 to 1.31219, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 239s 4s/step - loss: 0.5351 - val_loss: 1.3122\n",
      "Epoch 28/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4937\n",
      "Epoch 00028: val_loss improved from 1.31219 to 1.30803, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 124s 2s/step - loss: 0.4937 - val_loss: 1.3080\n",
      "Epoch 29/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4544\n",
      "Epoch 00029: val_loss improved from 1.30803 to 1.30617, saving model to MTmodel.h1.24_Aug_20\n",
      "INFO:tensorflow:Assets written to: MTmodel.h1.24_Aug_20/assets\n",
      "63/63 [==============================] - 133s 2s/step - loss: 0.4544 - val_loss: 1.3062\n",
      "Epoch 30/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4166\n",
      "Epoch 00030: val_loss did not improve from 1.30617\n",
      "63/63 [==============================] - 122s 2s/step - loss: 0.4166 - val_loss: 1.3131\n"
     ]
    }
   ],
   "source": [
    "filename = 'MTmodel.h1.24_Aug_20'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=30, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
